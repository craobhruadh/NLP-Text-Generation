{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources consulted in the process of making this\n",
    "\n",
    "https://machinelearningmastery.com/develop-character-based-neural-language-model-keras/\n",
    "\n",
    "https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\n",
    "\n",
    "http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "http://www.tensorflow.org/alpha/tutorials/text/text_generation\n",
    "\n",
    "\n",
    "### To read: Alternate?\n",
    "\n",
    "https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0\n",
    "\n",
    "https://jalammar.github.io/illustrated-transformer/\n",
    "\n",
    "http://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "\n",
    "https://arxiv.org/abs/1803.01271\n",
    "\n",
    "\n",
    "# Text Generation\n",
    "\n",
    "The general read in text as a sequence of characters, predict what the next character will be, with a LSTM/RNN\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "import time\n",
    "import re \n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#filename = 'hamlet3.txt'\n",
    "filename= 'complete_shakespeare.txt'\n",
    "\n",
    "### Below is the number of characters to read as a single input\n",
    "numCharacters = 100\n",
    "\n",
    "\n",
    "\n",
    "fid = open(filename, 'r',encoding='utf-8-sig')\n",
    "text = fid.read()\n",
    "fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5653528"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\nThe Complete Works of William Shakespeare\\n\\n\\n\\nby William Shakespeare\\n\\n\\n\\n\\n      Contents\\n\\n\\n\\n               THE SONNETS\\n\\n               ALL’S WELL THAT ENDS WELL\\n\\n               THE TRAGEDY OF ANTONY AND CLEOPATRA\\n\\n               AS YOU LIKE IT\\n\\n               THE COMEDY OF ERRORS\\n\\n               THE TRAGEDY OF CORIOLANUS\\n\\n               CYMBELINE\\n\\n               THE TRAGEDY OF HAMLET, PRINCE OF DENMARK\\n\\n               THE FIRST PART OF KING HENRY THE FOURTH\\n\\n               THE SECOND PART OF K'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il luck,\n",
      "Of plagues, of dearths, or seasons’ quality,\n",
      "Nor can I fortune to brief minutes tell;\n",
      "Pointing to each his thunder, rain and wind,\n",
      "Or say with princes if it shall go well\n",
      "By oft predict that I in heaven find.\n",
      "But from thine eyes my knowledge I derive,\n",
      "And constant stars in them I read such art\n",
      "As truth and beauty shall together thrive\n",
      "If from thy self, to store thou wouldst convert:\n",
      "  Or else of thee this I prognosticate,\n",
      "  Thy end is truth’s and beauty’s doom and date.\n",
      "\n",
      "\n",
      "              \n"
     ]
    }
   ],
   "source": [
    "print(text[10500:11000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5653528"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = list()\n",
    "\n",
    "for i in range(0, len(text)-numCharacters):\n",
    "    sequence = text[i:i+1+numCharacters]\n",
    "    segments.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to Paphos, where their queen\\n  Means to immure herself and not be seen.\\n\\n\\n    \\n\\n  FINIS\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " 'o Paphos, where their queen\\n  Means to immure herself and not be seen.\\n\\n\\n    \\n\\n  FINIS\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " ' Paphos, where their queen\\n  Means to immure herself and not be seen.\\n\\n\\n    \\n\\n  FINIS\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " 'Paphos, where their queen\\n  Means to immure herself and not be seen.\\n\\n\\n    \\n\\n  FINIS\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " 'aphos, where their queen\\n  Means to immure herself and not be seen.\\n\\n\\n    \\n\\n  FINIS\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " 'phos, where their queen\\n  Means to immure herself and not be seen.\\n\\n\\n    \\n\\n  FINIS\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " 'hos, where their queen\\n  Means to immure herself and not be seen.\\n\\n\\n    \\n\\n  FINIS\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " 'os, where their queen\\n  Means to immure herself and not be seen.\\n\\n\\n    \\n\\n  FINIS\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " 's, where their queen\\n  Means to immure herself and not be seen.\\n\\n\\n    \\n\\n  FINIS\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " ', where their queen\\n  Means to immure herself and not be seen.\\n\\n\\n    \\n\\n  FINIS\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for m,n in enumerate(unique_chars):\n",
    "#    print(m,n)\n",
    "\n",
    "unique_chars = sorted(set(text))\n",
    "\n",
    "character_integer_map = dict((character, integer) for integer, character in enumerate(unique_chars))\n",
    "\n",
    "integer_character_map = dict((integer, character) for integer, character in enumerate(unique_chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exact same as above but whatev\n",
    "#unique_chars = sorted(set(text))\n",
    "#character_integer_map ={u:i for i,u in enumerate(unique_chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 unique characters found\n"
     ]
    }
   ],
   "source": [
    "num_unique = len(character_integer_map)\n",
    "print(num_unique, 'unique characters found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n\\n\\nThe Complete Works of William Shakespeare\\n\\n\\n\\nby William Shakespeare\\n\\n\\n\\n\\n      Contents\\n\\n\\n\\n       ',\n",
       " '\\n\\n\\nThe Complete Works of William Shakespeare\\n\\n\\n\\nby William Shakespeare\\n\\n\\n\\n\\n      Contents\\n\\n\\n\\n        ',\n",
       " '\\n\\nThe Complete Works of William Shakespeare\\n\\n\\n\\nby William Shakespeare\\n\\n\\n\\n\\n      Contents\\n\\n\\n\\n         ',\n",
       " '\\nThe Complete Works of William Shakespeare\\n\\n\\n\\nby William Shakespeare\\n\\n\\n\\n\\n      Contents\\n\\n\\n\\n          ',\n",
       " 'The Complete Works of William Shakespeare\\n\\n\\n\\nby William Shakespeare\\n\\n\\n\\n\\n      Contents\\n\\n\\n\\n           ',\n",
       " 'he Complete Works of William Shakespeare\\n\\n\\n\\nby William Shakespeare\\n\\n\\n\\n\\n      Contents\\n\\n\\n\\n            ',\n",
       " 'e Complete Works of William Shakespeare\\n\\n\\n\\nby William Shakespeare\\n\\n\\n\\n\\n      Contents\\n\\n\\n\\n             ',\n",
       " ' Complete Works of William Shakespeare\\n\\n\\n\\nby William Shakespeare\\n\\n\\n\\n\\n      Contents\\n\\n\\n\\n              ',\n",
       " 'Complete Works of William Shakespeare\\n\\n\\n\\nby William Shakespeare\\n\\n\\n\\n\\n      Contents\\n\\n\\n\\n               ',\n",
       " 'omplete Works of William Shakespeare\\n\\n\\n\\nby William Shakespeare\\n\\n\\n\\n\\n      Contents\\n\\n\\n\\n               T']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total_characters = len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(0, num_total_characters - numCharacters, 1):\n",
    "    sequence = text[i:i + numCharacters]\n",
    "    sequence_out = text[i + numCharacters]\n",
    "    X_train.append([character_integer_map[x] for x in sequence])\n",
    "    y_train.append(character_integer_map[sequence_out])\n",
    "\n",
    "\n",
    "num_patterns = len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternate data prep method\n",
    "\n",
    "As taken from tensorflow tutorial on text generation (see links at top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_as_integer = np.array([character_integer_map[x] for x in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 26, 39, 29,  2, 28, 37, 30, 40, 41, 26, 45, 43, 26,  1,  1,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2, 26, 44,  2,\n",
       "       50, 40, 46,  2, 37, 34, 36, 30,  2, 34, 45,  1,  1,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2, 45, 33, 30,  2, 28, 40,\n",
       "       38, 30, 29, 50,  2, 40, 31,  2, 30, 43, 43, 40, 43, 44,  1,  1,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2, 45])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_integer[200:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' AND CLEOPATRA\\n\\n               AS YOU LIKE IT\\n\\n               THE COMEDY OF ERRORS\\n\\n               T'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([integer_character_map[x] for x in text_as_integer[200:300]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_per_epoch = len(text) // numCharacters\n",
    "\n",
    "character_dataset = tf.data.Dataset.from_tensor_slices(text_as_integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = character_dataset.batch(numCharacters+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n\\n\\n\\nThe Complete Works of William Shakespeare\\n\\n\\n\\nby William Shakespeare\\n\\n\\n\\n\\n      Contents\\n\\n\\n\\n       '\n",
      "'        THE SONNETS\\n\\n               ALL’S WELL THAT ENDS WELL\\n\\n               THE TRAGEDY OF ANTONY A'\n",
      "'ND CLEOPATRA\\n\\n               AS YOU LIKE IT\\n\\n               THE COMEDY OF ERRORS\\n\\n               THE '\n",
      "'TRAGEDY OF CORIOLANUS\\n\\n               CYMBELINE\\n\\n               THE TRAGEDY OF HAMLET, PRINCE OF DENM'\n",
      "'ARK\\n\\n               THE FIRST PART OF KING HENRY THE FOURTH\\n\\n               THE SECOND PART OF KING H'\n"
     ]
    }
   ],
   "source": [
    "idx2char = np.array(unique_chars)\n",
    "\n",
    "for i in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[i.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:] # this is everything previous, shifted over by one\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  '\\n\\n\\n\\nThe Complete Works of William Shakespeare\\n\\n\\n\\nby William Shakespeare\\n\\n\\n\\n\\n      Contents\\n\\n\\n\\n      '\n",
      "Output data:  '\\n\\n\\n\\nThe Complete Works of William Shakespeare\\n\\n\\n\\nby William Shakespeare\\n\\n\\n\\n\\n      Contents\\n\\n\\n\\n      '\n",
      "Input data:  '        THE SONNETS\\n\\n               ALL’S WELL THAT ENDS WELL\\n\\n               THE TRAGEDY OF ANTONY '\n",
      "Output data:  '        THE SONNETS\\n\\n               ALL’S WELL THAT ENDS WELL\\n\\n               THE TRAGEDY OF ANTONY '\n",
      "Input data:  'ND CLEOPATRA\\n\\n               AS YOU LIKE IT\\n\\n               THE COMEDY OF ERRORS\\n\\n               THE'\n",
      "Output data:  'ND CLEOPATRA\\n\\n               AS YOU LIKE IT\\n\\n               THE COMEDY OF ERRORS\\n\\n               THE'\n",
      "Input data:  'TRAGEDY OF CORIOLANUS\\n\\n               CYMBELINE\\n\\n               THE TRAGEDY OF HAMLET, PRINCE OF DEN'\n",
      "Output data:  'TRAGEDY OF CORIOLANUS\\n\\n               CYMBELINE\\n\\n               THE TRAGEDY OF HAMLET, PRINCE OF DEN'\n",
      "Input data:  'ARK\\n\\n               THE FIRST PART OF KING HENRY THE FOURTH\\n\\n               THE SECOND PART OF KING '\n",
      "Output data:  'ARK\\n\\n               THE FIRST PART OF KING HENRY THE FOURTH\\n\\n               THE SECOND PART OF KING '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(5):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Output data: ', repr(''.join(idx2char[input_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Shuffle in data off a buffer, rather than keep entire sequence in memory\n",
    "buffer_size = 10000\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 256\n",
    "\n",
    "rnn_units = 512\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dimension, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dimension, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "#def build_model(vocab_size, embedding_dimension, rnn_units, batch_size):\n",
    "#    model = tf.keras.Sequential([\n",
    "#        tf.keras.layers.Embedding(vocab_size, embedding_dimension, batch_input_shape=[batch_size, None]),\n",
    "#        tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "#        tf.keras.layers.LSTM(rnn_units, return_sequences=True),\n",
    "#        tf.keras.layers.Dense(vocab_size)\n",
    "#    ])\n",
    "#    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size = num_unique, \n",
    "                    embedding_dimension=embedding_dimension, \n",
    "                    rnn_units=rnn_units, \n",
    "                    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 93)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (64, None, 256)           23808     \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (64, None, 512)           1574912   \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (64, None, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (64, None, 93)            47709     \n",
      "=================================================================\n",
      "Total params: 3,745,629\n",
      "Trainable params: 3,745,629\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sample_index = tf.squeeze(sample_index, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9,  8, 32, 66, 49, 25, 75, 64, 81, 43, 89, 56, 85, 70, 37,  4, 83,\n",
       "       42, 24, 84, 77, 44, 67, 24, 91, 73, 82, 11, 85,  1,  5, 56, 19, 92,\n",
       "       14, 66, 46, 56, 56, 74,  9, 79,  2, 85,  9, 63, 86, 36, 43, 26, 59,\n",
       "       39, 85, 45, 88, 64, 29, 33, 13, 67, 72, 28, 43, 28, 20, 80, 58, 80,\n",
       "        5, 53, 51,  0,  4, 87,  3, 47, 41, 31, 25, 88, 33, 62, 75, 82, 44,\n",
       "       11, 82, 20, 21, 33, 18, 82,  0, 40, 25, 87, 56, 80, 30,  5])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "   Desir'd more than constrain'd. To satisfy,\n",
      "    If of my freedom 'tis the main part, take\n",
      "    No s\n",
      "\n",
      "Output:\n",
      "*)GjX?shyR‘`ÆnL\"|Q;}uSk;“qz-Æ\n",
      "&`6”1jU``r*w Æ*gàKRAcNÆT—hDH0kpCRC7xbx&\\Z\t\"æ!VPF?—HfszS-z78H5z\tO?æ`xE&\n"
     ]
    }
   ],
   "source": [
    "# Note that for a random/glorot uniform initialization on an untrained network the result is random gibberish\n",
    "\n",
    "print('Input:')\n",
    "print(''.join(idx2char[input_example_batch[0]]))\n",
    "\n",
    "print()\n",
    "print('Output:')\n",
    "print(''.join(idx2char[sample_index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 93)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar loss:  4.531937\n"
     ]
    }
   ],
   "source": [
    "# Define loss function\n",
    "# At this point it's a simple multiclass classification problem \n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print('Prediction shape: ', example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print('scalar loss: ', example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(), loss=loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model checkpoints to make sure they're saved\n",
    "path = './training_checkpoints'\n",
    "\n",
    "checkpoint_prefix = os.path.join(path, \"checkpoint_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_prefix, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./training_checkpoints/checkpoint_9\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Checkpointable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.recurrent.LSTM object at 0xb5ec65a58> and <tensorflow.python.keras.layers.core.Dense object at 0xb5657cd30>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0xb6522ce48>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call this line only if you want to load previous checkpoints\n",
    "print(tf.train.latest_checkpoint(path))\n",
    "model.load_weights(tf.train.latest_checkpoint(path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 303s 3s/step - loss: 1.9524\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 300s 3s/step - loss: 1.6110\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 302s 3s/step - loss: 1.5291\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 307s 3s/step - loss: 1.4772\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 297s 3s/step - loss: 1.4210\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 299s 3s/step - loss: 1.4109\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 300s 3s/step - loss: 1.4048\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 286s 3s/step - loss: 1.4215\n",
      "Epoch 9/10\n",
      " 74/100 [=====================>........] - ETA: 1:14 - loss: 1.4023WARNING:tensorflow:Your dataset iterator ran out of data.\n",
      " 74/100 [=====================>........] - ETA: 1:14 - loss: 1.4023"
     ]
    }
   ],
   "source": [
    "numEpochs = 10\n",
    "\n",
    "\n",
    "history = model.fit(dataset, epochs=numEpochs,steps_per_epoch=100, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints/checkpoint_9'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size = num_unique, \n",
    "                    embedding_dimension=embedding_dimension, \n",
    "                    rnn_units=rnn_units, \n",
    "                    batch_size=1)\n",
    "\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(path +'/Single Layer LSTM'))\n",
    "#model.load_weights('./training_checkpoints/checkpoint_9')\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (1, None, 256)            23808     \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (1, None, 512)            1574912   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (1, None, 93)             47709     \n",
      "=================================================================\n",
      "Total params: 1,646,429\n",
      "Trainable params: 1,646,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Note: setting temperature higher leads to more surprising results\n",
    "# Setting it lower leads to more predictable results\n",
    "def generate_text(model, start_string, num_generate = 1000, temperature = 1.0):\n",
    "    input_eval = [character_integer_map[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    generated_text = []\n",
    "    \n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        \n",
    "        # Remove batch dimensions\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        # Use a categorial distribution to predict word returned by model\n",
    "        predictions = predictions/ temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        \n",
    "        # Pass predicted word as next input of model, along with previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        \n",
    "        generated_text.append(idx2char[predicted_id])\n",
    "        \n",
    "    return ''.join(generated_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eful band.\n",
      "\n",
      "GRIMON.\n",
      "My child-bign.\n",
      "\n",
      "STARDAMUS.\n",
      "Why, then?\n",
      "\n",
      "SERVOLIO.\n",
      "Nay, 'long, and pleading, and so?\n",
      "Here’s honest me, desire\n",
      "    In their govern'd, May is o you Note sently sir my helf, be ranger,\n",
      "    And the earth shade the ring mad shall, we keep the day\n",
      "    That you was soth some owl wanton's hand;\n",
      "    Springs, but I'll capint steep, 'emembrest,\n",
      "    Their hauds she saide.      [MIOLA.\n",
      "      The worls way unfaviclity ball.\n",
      "    Afore your villainm's eaga swor from frain.\n",
      "                                             Exent\n",
      "\n",
      "                          In another son Ary.\n",
      "  CAMLIBALIA. Whereine have you see you my lord is thinr Scerts\n",
      "    Nay from the act and lookely.\n",
      "  MIRANDARD. So speak;\n",
      "Haroust to call hims to other; where ne'er his very doth come quoth me, my lord.\n",
      "IS was herselfes are they love so;\n",
      "And go, that I know a kind in ither, 'tis; but itle I have was all with to him for\n",
      "Where gavis juce to the heart with made part in atsel:\n",
      "  DIO. That's not will desides thy farbanly arp\n",
      "CPU times: user 8.55 s, sys: 36.5 ms, total: 8.59 s\n",
      "Wall time: 8.6 s\n"
     ]
    }
   ],
   "source": [
    "%time print(generate_text(model, 'Once more into the breach'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Older code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation\n",
    "\n",
    "To do: \n",
    "\n",
    "1. Get data into format: [samples, time steps, features]\n",
    "\n",
    "2. Normalize X_train to be between 0 and 1\n",
    "\n",
    "3. Turn the output vector Y_train to be categorical variables using one-hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (num_patterns , numCharacters, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / num_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "y = np_utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190407, 50, 1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 26368/190407 [===>..........................] - ETA: 15:26 - loss: 3.0961"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-3b52a639a8c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape =( X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256,return_sequences=True))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "\n",
    "filepath=\"weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# fit the model\n",
    "model.fit(X_train, y, epochs=20, batch_size=128, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using trained model to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = ''\n",
    "#model.load_weights(filename)\n",
    "\n",
    "pattern = X_train[np.random.randint(0,len(X_train)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numToGenerate = 2000\n",
    "\n",
    "for i in range(numToGenerate):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = integer_character_map[index]\n",
    "    seq_in = [integer_character_map[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print \"\\nDone.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "\n",
    "following links were helpful for references debugging\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "\n",
    "http://www.jessicayung.com/lstms-for-time-series-in-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1, num_layers = 2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "        \n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return(torch.zeros(self.num_layers, self.batch_size, self.hidden_dim), \n",
    "               torch.zeros(self.num_layers,self.batch_size, self.hidden_dim))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        lstm_out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))\n",
    "        y_pred = self.linear(lstm_out[-1].view(self.batch_size, -1))\n",
    "        return y_pred.view(-1)\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = torch.from_numpy(X_train).type(torch.Tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rcheung/anaconda3/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 50, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-db81fa1d5501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;31m#loss = loss_fn(y_pred, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-7e8632206034>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0m_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rnn_impls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    133\u001b[0m             raise RuntimeError(\n\u001b[1;32m    134\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 135\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_input_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 50, got 1"
     ]
    }
   ],
   "source": [
    "#numEpochs = 50\n",
    "#batch_size = 50\n",
    "#learning_rate = 0.1\n",
    "#hidden_dimension = 3\n",
    "#\n",
    "#model = LSTM(numCharacters, hidden_dimension, batch_size, 1, 3)\n",
    "#\n",
    "#loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "#\n",
    "#optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#\n",
    "#performance_data  = np.zeros(numEpochs)\n",
    "#\n",
    "#for i in range(numEpochs):\n",
    "#    model.zero_grad()\n",
    "#    \n",
    "#    model.hidden = model.init_hidden()\n",
    "#    y_pred = model(X_train)\n",
    "#    optimiser.zero_grad()\n",
    "#    \n",
    "#    loss.backward()\n",
    "#    \n",
    "#    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
